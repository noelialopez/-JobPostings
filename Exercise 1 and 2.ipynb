{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noelialopez83/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/noelialopez83/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import re\n",
    "# Getting that SKLearn Dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "#Gridsearch and scoring\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Category</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>salary_mean</th>\n",
       "      <th>Salary_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14677</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Bolton Clarke</td>\n",
       "      <td>Give yourself a pay rise - eligibility for up ...</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Strong understanding of business analytics too...</td>\n",
       "      <td>Business Performance Analyst</td>\n",
       "      <td>15900.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25428</th>\n",
       "      <td>Data Consultant</td>\n",
       "      <td>Robert Half Australia</td>\n",
       "      <td>Are you a sales superstar? Great opportunity t...</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>Great opportunity to join a large team as a Cu...</td>\n",
       "      <td>Telesales Consultant | $53K + Super | Temp to ...</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8896</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>Swinburne University of Technology</td>\n",
       "      <td>Faculty of Science, Engineering and Technology...</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>A 3 year fully-funded PhD scholarship is avail...</td>\n",
       "      <td>PhD Scholarship – Big Data Analytics for Oil D...</td>\n",
       "      <td>25849.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25510</th>\n",
       "      <td>Data Consultant</td>\n",
       "      <td>Kennedy Reid</td>\n",
       "      <td>The recruitment industry is one that is overlo...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>High data entry speed and excellent attention ...</td>\n",
       "      <td>Recruitment Administrator</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15837</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Janison Solutions</td>\n",
       "      <td>THE GIGThe Learning Support Specialist primary...</td>\n",
       "      <td>Coffs Harbour NSW</td>\n",
       "      <td>Our passion for excellence, innovation and per...</td>\n",
       "      <td>Learning Support Specialist</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Job Category                             company  \\\n",
       "14677  Business Analyst                       Bolton Clarke   \n",
       "25428   Data Consultant               Robert Half Australia   \n",
       "8896           Big Data  Swinburne University of Technology   \n",
       "25510   Data Consultant                        Kennedy Reid   \n",
       "15837  Business Analyst                   Janison Solutions   \n",
       "\n",
       "                                             description           location  \\\n",
       "14677  Give yourself a pay rise - eligibility for up ...          Australia   \n",
       "25428  Are you a sales superstar? Great opportunity t...      Melbourne VIC   \n",
       "8896   Faculty of Science, Engineering and Technology...      Melbourne VIC   \n",
       "25510  The recruitment industry is one that is overlo...         Sydney NSW   \n",
       "15837  THE GIGThe Learning Support Specialist primary...  Coffs Harbour NSW   \n",
       "\n",
       "                                                 summary  \\\n",
       "14677  Strong understanding of business analytics too...   \n",
       "25428  Great opportunity to join a large team as a Cu...   \n",
       "8896   A 3 year fully-funded PhD scholarship is avail...   \n",
       "25510  High data entry speed and excellent attention ...   \n",
       "15837  Our passion for excellence, innovation and per...   \n",
       "\n",
       "                                                   title  salary_mean  \\\n",
       "14677                       Business Performance Analyst      15900.0   \n",
       "25428  Telesales Consultant | $53K + Super | Temp to ...      25000.0   \n",
       "8896   PhD Scholarship – Big Data Analytics for Oil D...      25849.0   \n",
       "25510                          Recruitment Administrator      42500.0   \n",
       "15837                        Learning Support Specialist      42500.0   \n",
       "\n",
       "       Salary_type  \n",
       "14677            0  \n",
       "25428            0  \n",
       "8896             0  \n",
       "25510            0  \n",
       "15837            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read my_scraping_final.xlsx into a DataFrame\n",
    "salary = pd.read_excel(\"../Noelia/my_scraping_final.xlsx\")\n",
    "salary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the count of the low and high salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">salary_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>546.0</td>\n",
       "      <td>81659.589744</td>\n",
       "      <td>14561.242243</td>\n",
       "      <td>15900.0</td>\n",
       "      <td>72500.0</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>92500.0</td>\n",
       "      <td>103103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>557.0</td>\n",
       "      <td>132631.139138</td>\n",
       "      <td>25514.445571</td>\n",
       "      <td>103379.0</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>260000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            salary_mean                                                   \\\n",
       "                  count           mean           std       min       25%   \n",
       "Salary_type                                                                \n",
       "0                 546.0   81659.589744  14561.242243   15900.0   72500.0   \n",
       "1                 557.0  132631.139138  25514.445571  103379.0  115000.0   \n",
       "\n",
       "                                           \n",
       "                  50%       75%       max  \n",
       "Salary_type                                \n",
       "0             85000.0   92500.0  103103.0  \n",
       "1            125000.0  140000.0  260000.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gest the description of the column 'Salary_type'\n",
    "salary.groupby('Salary_type').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I would like to do NLP to check out the importance of the words in the description column, which words appear the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defines X and y\n",
    "X = salary['description']\n",
    "y = salary.Salary_type\n",
    "\n",
    "# splits the new DataFrame into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out now our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5049864007252947"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_line= np.mean(salary.Salary_type)\n",
    "base_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1103"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(salary['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1103"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(salary.Salary_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use CountVectorizer to convert the training and testing text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use CountVectorizer to create document-term matrices from X_train and X_test\n",
    "vect = CountVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "# Fit our vectorizer using our train data\n",
    "vect.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87495"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check the length of our data that is in a vectorized state\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transforming our x_train data using our fit vect.\n",
    "# And converting the result to a DataFrame.\n",
    "XX_train = pd.DataFrame(vect.transform(X_train).todense(),\n",
    "                       columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data           3193\n",
       "experience     2602\n",
       "business       1844\n",
       "work           1652\n",
       "team           1455\n",
       "role           1422\n",
       "skills         1389\n",
       "development    1017\n",
       "working        1009\n",
       "research        974\n",
       "management      920\n",
       "support         798\n",
       "position        798\n",
       "ability         793\n",
       "information     791\n",
       "apply           775\n",
       "strong          730\n",
       "analysis        678\n",
       "science         656\n",
       "including       631\n",
       "services        629\n",
       "analytics       611\n",
       "technical       594\n",
       "new             592\n",
       "learning        589\n",
       "client          589\n",
       "time            587\n",
       "technology      570\n",
       "provide         565\n",
       "high            562\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which words appear the most?\n",
    "word_counts = XX_train.sum(axis=0)\n",
    "word_counts.sort_values(ascending = False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pipeline is a way for us to construct a function to execute the same tasks continuously in our variable model we fit a vectorizer, and a model our Model variable is stored with the fit vectorizer and model so we we call model.xxxx it uses that information stored.\n",
    "We are gonna create a function to try the different models and see with which one I get better resaults.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the different Models to see which one suits better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Lemmatizing method to see if our score improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates the Lemmatokenizer class\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates a function to try the different models and print out the score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def Models_Acc(XTrain, yTrain, XTest, yTest, ngramRange=(1, 2)):\n",
    "    for Vect in range(1,13):\n",
    "        if Vect == 1:\n",
    "            model = make_pipeline(HashingVectorizer(stop_words='english',\n",
    "                                                    non_negative=True,\n",
    "                                                    n_features=2**16),\n",
    "                    LogisticRegression()\n",
    "\n",
    "            )\n",
    "            print '-----------------------------------------------------------------------------------------'\n",
    "            print 'Hashing Vectorizer and Logistic Regression'\n",
    "        elif Vect == 2:\n",
    "            model = make_pipeline(TfidfVectorizer(stop_words='english',\n",
    "                                          sublinear_tf=True,\n",
    "                                          max_df=0.5,\n",
    "                                          max_features=1000,\n",
    "                                          ngram_range=ngramRange),\n",
    "                    LogisticRegression()\n",
    "                          )\n",
    "            print '-----------------------------------------------------------------------------------------'\n",
    "            print 'TfidfVectorizer using {} ngram and Logistic Regression'.format(ngramRange)\n",
    "            \n",
    "        elif Vect == 3:\n",
    "            model = make_pipeline(CountVectorizer(stop_words='english', ngram_range=ngramRange),\n",
    "                          LogisticRegression()\n",
    "                          )\n",
    "            print '-----------------------------------------------------------------------------------------'\n",
    "            print 'CountVectorizer with {} ngram and Logistic Regression'.format(ngramRange)\n",
    "            \n",
    "        elif Vect == 5: \n",
    "            model = make_pipeline(CountVectorizer(stop_words='english', ngram_range=ngramRange, tokenizer=LemmaTokenizer()),\n",
    "                          LogisticRegression()\n",
    "                          )\n",
    "            print '-----------------------------------------------------------------------------------------'\n",
    "            print 'CountVectorizer with LemmaTokenizer and {} ngram and Logistic Regression'.format(ngramRange)\n",
    "            \n",
    "        elif Vect == 6:\n",
    "            model = make_pipeline(CountVectorizer(stop_words='english', ngram_range=ngramRange),\n",
    "                          DecisionTreeClassifier(),\n",
    "                      )\n",
    "            print '-----------------------------------------------------------------------------------------'\n",
    "            print 'CountVectorizer with {} and MultinomialNB Regression'.format(ngramRange)\n",
    "        elif Vect == 7:\n",
    "            model = make_pipeline(CountVectorizer(stop_words='english', ngram_range=ngramRange),\n",
    "                          RandomForestClassifier(),\n",
    "                      )\n",
    "            print '-----------------------------------------------------------------------------------------'\n",
    "            print 'CountVectorizer with {} and Random Forest Regression'.format(ngramRange)\n",
    "        elif Vect == 8:\n",
    "            model = make_pipeline(CountVectorizer(stop_words='english', ngram_range=ngramRange),\n",
    "                          DecisionTreeClassifier())\n",
    "            print '-----------------------------------------------------------------------------------------'\n",
    "            print 'CountVectorizer with {} and Decision Tree'.format(ngramRange)\n",
    "        elif Vect == 9:\n",
    "            model = make_pipeline(CountVectorizer(stop_words='english', ngram_range=ngramRange),\n",
    "                          AdaBoostClassifier())\n",
    "            print '-----------------------------------------------------------------------------------------'\n",
    "            print 'CountVectorizer with {} and AdaBoost'.format(ngramRange)\n",
    "        elif Vect == 10:\n",
    "            model = make_pipeline(TfidfVectorizer(stop_words='english',\n",
    "                                          sublinear_tf=True,\n",
    "                                          max_df=0.5,\n",
    "                                          max_features=1000,\n",
    "                                          ngram_range=ngramRange),\n",
    "                    DecisionTreeClassifier()\n",
    "                          )\n",
    "            print '-----------------------------------------------------------------------------------------'\n",
    "            print 'TfidfVectorizer using {} ngram and DecisionTreeClassifier'.format(ngramRange)\n",
    "        elif Vect ==11:\n",
    "            model = make_pipeline(TfidfVectorizer(stop_words='english',\n",
    "                                          sublinear_tf=True,\n",
    "                                          max_df=0.5,\n",
    "                                          max_features=1000,\n",
    "                                          ngram_range=ngramRange),\n",
    "                    RandomForestClassifier()\n",
    "                          )\n",
    "            print '-----------------------------------------------------------------------------------------'\n",
    "            print 'TfidfVectorizer using {} ngram and RandomForestClassifier'.format(ngramRange) \n",
    "        elif Vect == 12:\n",
    "            model = make_pipeline(CountVectorizer(stop_words='english', ngram_range=ngramRange, tokenizer=LemmaTokenizer()),\n",
    "                                  SVC(kernel='linear'))\n",
    "            print '-----------------------------------------------------------------------------------------'\n",
    "            print 'CountVectorizer with LemmaTokenizer with {} and SVM'.format(ngramRange)\n",
    "        model.fit(XTrain, yTrain)\n",
    "        y_pred = model.predict(XTest)\n",
    "        print 'Accuracy:',accuracy_score(yTest, y_pred)\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the function we've created before to see what model performs better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "Hashing Vectorizer and Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noelialopez83/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/noelialopez83/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/noelialopez83/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.812688821752\n",
      "-----------------------------------------------------------------------------------------\n",
      "TfidfVectorizer using (2, 2) ngram and Logistic Regression\n",
      "Accuracy: 0.827794561934\n",
      "-----------------------------------------------------------------------------------------\n",
      "CountVectorizer with (2, 2) ngram and Logistic Regression\n",
      "Accuracy: 0.870090634441\n",
      "Accuracy: 0.870090634441\n",
      "-----------------------------------------------------------------------------------------\n",
      "CountVectorizer with LemmaTokenizer and (2, 2) ngram and Logistic Regression\n",
      "Accuracy: 0.873111782477\n",
      "-----------------------------------------------------------------------------------------\n",
      "CountVectorizer with (2, 2) and MultinomialNB Regression\n",
      "Accuracy: 0.821752265861\n",
      "-----------------------------------------------------------------------------------------\n",
      "CountVectorizer with (2, 2) and Random Forest Regression\n",
      "Accuracy: 0.809667673716\n",
      "-----------------------------------------------------------------------------------------\n",
      "CountVectorizer with (2, 2) and Decision Tree\n",
      "Accuracy: 0.818731117825\n",
      "-----------------------------------------------------------------------------------------\n",
      "CountVectorizer with (2, 2) and AdaBoost\n",
      "Accuracy: 0.767371601208\n",
      "-----------------------------------------------------------------------------------------\n",
      "TfidfVectorizer using (2, 2) ngram and DecisionTreeClassifier\n",
      "Accuracy: 0.794561933535\n",
      "-----------------------------------------------------------------------------------------\n",
      "TfidfVectorizer using (2, 2) ngram and RandomForestClassifier\n",
      "Accuracy: 0.824773413897\n",
      "-----------------------------------------------------------------------------------------\n",
      "CountVectorizer with LemmaTokenizer with (2, 2) and SVM\n",
      "Accuracy: 0.873111782477\n"
     ]
    }
   ],
   "source": [
    "Models_Acc(X_train, y_train, X_test, y_test, ngramRange=(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Gridsearching to get the best performance parameters to use them in our models and see how they go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        st...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'vect__ngram_range': ((1, 1), (1, 2), (2, 2), (1, 3)), 'vect__stop_words': ['english']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('mult', LogisticRegression()),\n",
    "])\n",
    "CV_parameters = { 'vect__ngram_range':((1, 1),(1, 2), (2, 2), (1, 3)),\n",
    "                  'vect__stop_words': ['english'],\n",
    "}\n",
    "CV_gridsearch = GridSearchCV(pipeline, CV_parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "CV_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835492227979\n",
      "{'vect__ngram_range': (2, 2), 'vect__stop_words': 'english'}\n",
      "0.870090634441\n"
     ]
    }
   ],
   "source": [
    "print CV_gridsearch.best_score_\n",
    "print CV_gridsearch.best_params_\n",
    "\n",
    "predictions = CV_gridsearch.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(classification_report(predictions,y_test))\n",
    "print(confusion_matrix(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7643504531722054"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X = salary['summary']\n",
    "y = salary.Salary_type\n",
    "\n",
    "# split the new DataFrame into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=101)\n",
    "\n",
    "# Lets use the stop_words argument to remove words like \"and, the, a\"\n",
    "cvec = CountVectorizer(stop_words='english', ngram_range=(2,2))\n",
    "\n",
    "# Fit our vectorizer using our train data\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train = pd.DataFrame(cvec.transform(X_train).todense(),\n",
    "                       columns=cvec.get_feature_names())\n",
    "X_test = pd.DataFrame(cvec.transform(X_test).todense(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "#Import and fit our logistic regression and test it too\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[144  23]\n",
      " [ 55 109]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.86      0.79       167\n",
      "          1       0.83      0.66      0.74       164\n",
      "\n",
      "avg / total       0.77      0.76      0.76       331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lr.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns  =  np.array(cvec.get_feature_names())\n",
    "# def list_important_pred_var(data):\n",
    "#     important_pred_var = pd.DataFrame(data, columns = [\"coef\"], index = columns)\n",
    "#     return important_pred_var.sort_values([\"coef\"], ascending = False)[:30]\n",
    "\n",
    "# list_important_pred_var(lr.coef_.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's get now our original data with the Articles that didn't have salary to predict if they are Jobs with low or high salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Articles_nan_Salary = pd.read_excel(\"../Noelia/my_original_scraping_with_description_and_nulls.xlsx\")\n",
    "Articles_nan_Salary = Articles_nan_Salary[Articles_nan_Salary[\"salary\"].isnull()]\n",
    "Articles_nan_Salary.head()\n",
    "test = pd.DataFrame(cvec.transform(Articles_nan_Salary[\"description\"]).todense(),\n",
    "                       columns=cvec.get_feature_names())\n",
    "Articles_nan_Salary[\"salary\"] = lr.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Category</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Metigy</td>\n",
       "      <td>@metigy we are creating the next generation of...</td>\n",
       "      <td>Sydney NSW 2000</td>\n",
       "      <td>1</td>\n",
       "      <td>Because of the nature of our platform, Data Sc...</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>HDR</td>\n",
       "      <td>HDR specializes in architecture, engineering, ...</td>\n",
       "      <td>Sydney NSW 2000</td>\n",
       "      <td>1</td>\n",
       "      <td>Continuously learn and develop new skills in d...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>International Institute of Data &amp; Analytics</td>\n",
       "      <td>The International Institute of Data &amp; Analytic...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>In data science and big data analytics, the ID...</td>\n",
       "      <td>Junior Data Analyst/Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>SAI Global</td>\n",
       "      <td>At SAI Global, we make Intelligent Risk possib...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Analytics or data science team in a commercial...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Velrada</td>\n",
       "      <td>Giving you the platform to succeed:\\nWorking o...</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>1</td>\n",
       "      <td>With a background in development across Data M...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>BuildingIQ</td>\n",
       "      <td>Job Description | Location – Sydney, Australia...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>We are looking for a Data Scientist to be a pa...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Fortune Select</td>\n",
       "      <td>Location: Sydney\\n\\nJob Type: Permanent\\n\\nSki...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>3+ years proven career history in Data science...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>BCG Digital Ventures</td>\n",
       "      <td>Syphen is on the mission to unlock the potenti...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Significant experience in data science field. ...</td>\n",
       "      <td>Data Scientist - Machine Learning Data Platform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Arup</td>\n",
       "      <td>Data Scientist (SYDDO)\\nPrimary Location: Aust...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Experience in applying data science methods to...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>SiteMinder</td>\n",
       "      <td>SiteMinder is the chosen solution for over , h...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Data science, analytics, economic consulting);...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Google</td>\n",
       "      <td>Google Technical Services: Professional Servic...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Engage various stakeholders, assess data readi...</td>\n",
       "      <td>Data Scientist, Google Technical Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Sterning</td>\n",
       "      <td>This is an amazing opportunity to step out fro...</td>\n",
       "      <td>Sydney NSW 2000</td>\n",
       "      <td>1</td>\n",
       "      <td>This is an amazing opportunity to step out fro...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>QBE Insurance</td>\n",
       "      <td>Apply scientific principles to business proces...</td>\n",
       "      <td>Sydney NSW 2000</td>\n",
       "      <td>1</td>\n",
       "      <td>Good understanding of Data Science domain, sta...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Yield AgTech Solutions</td>\n",
       "      <td>About us\\nThe Yield is hiring. Come join us to...</td>\n",
       "      <td>Sydney NSW 2000</td>\n",
       "      <td>1</td>\n",
       "      <td>Time series data, predictive atmospheric model...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>HDR</td>\n",
       "      <td>Data Scientist - ()\\nDescription\\n\\nHDR specia...</td>\n",
       "      <td>North Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Continuously learn and develop new skills in d...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Qantas Airways Limited</td>\n",
       "      <td>Data Scientist\\nGreenfield Data Science roles ...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Greenfield Data Science roles in this fast gro...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>Be a key part of our growth &amp; innovation strat...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Using Data Science techniques and Machine Lear...</td>\n",
       "      <td>Data &amp; Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>Leadership opportunity in consulting (Associat...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Using Data Science techniques and Machine Lear...</td>\n",
       "      <td>Data &amp; Analytics - Leadership role</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Google</td>\n",
       "      <td>Google's software engineers develop the next-g...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>BS degree in Computer Science, similar technic...</td>\n",
       "      <td>Software Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Iconic</td>\n",
       "      <td>THE ICONIC is a truly unique brand. We entered...</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>At The Iconic, we’d like to think of our Data ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>The Microsoft Malware Protection Center (MMPC)...</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>1</td>\n",
       "      <td>A Masters or Ph.D degree with coursework in St...</td>\n",
       "      <td>Data &amp; Applied Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>nbn™</td>\n",
       "      <td>As nbn is moving to the scale phase, in parall...</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>1</td>\n",
       "      <td>Work closely with data engineers to supporting...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Melbourne IT Group</td>\n",
       "      <td>Apply now\\n\\nDiscipline:\\nData and Analytics\\n...</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>1</td>\n",
       "      <td>Data and Analytics. At InfoReady we’re passion...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Wipro Limited</td>\n",
       "      <td>Wipro's Data Scientists help our clients disco...</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>1</td>\n",
       "      <td>Experience with common data science toolkits, ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>HelloFresh</td>\n",
       "      <td>About HelloFresh\\n\\nWe are the leading global ...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>0</td>\n",
       "      <td>You have at least 1-year previous experience w...</td>\n",
       "      <td>Junior Data Analyst - Internship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Capgemini Australia</td>\n",
       "      <td>About the role\\nWe are looking for a Data Scie...</td>\n",
       "      <td>Adelaide SA</td>\n",
       "      <td>1</td>\n",
       "      <td>Experience using Data Science tools (e.g. Clou...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Healthdirect Australia</td>\n",
       "      <td>The Data Analyst extracts, analyses and interp...</td>\n",
       "      <td>Sydney Central Business District NSW</td>\n",
       "      <td>0</td>\n",
       "      <td>Effective management of assigned Healthdirect ...</td>\n",
       "      <td>Junior-Data-and-Reporting-Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>Business today operates at the pinnacle of the...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>The successful candidate is an engineer with a...</td>\n",
       "      <td>Research Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>CS Energy</td>\n",
       "      <td>Back to Current Vacancies\\n\\nData Scientist\\n\\...</td>\n",
       "      <td>Brisbane QLD</td>\n",
       "      <td>1</td>\n",
       "      <td>As a member of the Asset Analytics team, the D...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Infoready</td>\n",
       "      <td>This is an opportunity for you to join Austral...</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Vizualisation experience. At InfoReady we...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Piktochart</td>\n",
       "      <td>The team in charged of data analysis in Piktoc...</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>1</td>\n",
       "      <td>Performed in-depth analyses on data of various...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Coffey</td>\n",
       "      <td>This role is more than a desk job. It’s about ...</td>\n",
       "      <td>Brisbane QLD</td>\n",
       "      <td>0</td>\n",
       "      <td>Tertiary qualifications in Science, Environmen...</td>\n",
       "      <td>Environmental Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>ANZ Banking Group</td>\n",
       "      <td>Willing to learn/train in Hadoop (Cloudera) ad...</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>1</td>\n",
       "      <td>Experience in data warehousing concepts, files...</td>\n",
       "      <td>Big Data Platform Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Cardno</td>\n",
       "      <td>Job Description\\nCardno is an ASX listed profe...</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>0</td>\n",
       "      <td>Analysis and presentation of data. A keen inte...</td>\n",
       "      <td>Environmental Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Domain Group</td>\n",
       "      <td>A little about us:\\nThere has never been a mor...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>MS or PhD degree in Computer Science, Artifici...</td>\n",
       "      <td>Software Engineer - Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Akuna Capital</td>\n",
       "      <td>About Akuna:\\nAkuna Capital is a young and boo...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Masters or PhD in Statistics, Computer Science...</td>\n",
       "      <td>Junior Quantitative Researcher - Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Pharmaceutical &amp; Medical Professionals</td>\n",
       "      <td>Ongoing assignment offering full time hours.\\n...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>0</td>\n",
       "      <td>Data entry into current system. A Medical Scie...</td>\n",
       "      <td>Medical Science Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>Amazon has an immediate opening for an FBA Sup...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>0</td>\n",
       "      <td>Ability to analyze data and metrics. Bachelor’...</td>\n",
       "      <td>Process Analyst - Supply Chain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Akuna Capital</td>\n",
       "      <td>About Akuna:\\nAkuna Capital is a young and boo...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Being a Quantitative Developer with the Data t...</td>\n",
       "      <td>Quantitative Developer- Data Analysis, Cryptoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Akuna Capital</td>\n",
       "      <td>About Akuna:\\nAkuna Capital is a young and boo...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Being a Quantitative Developer with the Data t...</td>\n",
       "      <td>Quantitative Developer- Data Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Children's Cancer Institute</td>\n",
       "      <td>Innovative, collaborative and positive team-or...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>0</td>\n",
       "      <td>Experience with microarrays, next-generation s...</td>\n",
       "      <td>Bioinformatician/ Computational Biologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Georgiou</td>\n",
       "      <td>Georgiou is a national building construction a...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Assisting in data entry, coordinating monthly ...</td>\n",
       "      <td>Environmental Cadet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Optus</td>\n",
       "      <td>Join a company dedicated to your career develo...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Mastery of calling APIs, ingesting data, trans...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Servian</td>\n",
       "      <td>The opportunity\\nThis is a great opportunity f...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Data &amp; Analytics - BI/DW, Big Data Analytics, ...</td>\n",
       "      <td>Data Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Johnson &amp; Johnson Family of Companies</td>\n",
       "      <td>Permanent role\\nLeading products - Gastroenter...</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>0</td>\n",
       "      <td>Medical Science Liaison. As a Medical Science ...</td>\n",
       "      <td>Medical Scientific Liaison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Job Description\\nResearch Scientist- AI Soluti...</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>1</td>\n",
       "      <td>At least two years of experience after a Docto...</td>\n",
       "      <td>Research Scientist- AI Solutions Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Children's Cancer Institute</td>\n",
       "      <td>Innovative, collaborative and positive team-or...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>0</td>\n",
       "      <td>Tertiary qualifications in science or relevant...</td>\n",
       "      <td>Research Assistant - Molecular Profiling (PM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Digital Alchemy</td>\n",
       "      <td>We're looking for a consultative individual wh...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Relevant degree in Computer Science, ICT, Scie...</td>\n",
       "      <td>Business Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>DELL</td>\n",
       "      <td>Graduate Opportunities at Dell EMC (x  roles)\\...</td>\n",
       "      <td>North Ryde NSW</td>\n",
       "      <td>0</td>\n",
       "      <td>Computer Science or Engineering degree (gradua...</td>\n",
       "      <td>Graduate Technical Support Engineer (x 24 roles)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Cushman &amp; Wakefield</td>\n",
       "      <td>The Data &amp; Reporting Analyst is a client Accou...</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>0</td>\n",
       "      <td>Document data reporting processes and identify...</td>\n",
       "      <td>Data &amp; Reporting Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>Pioneer uses the science of the lab and the la...</td>\n",
       "      <td>Wyreema QLD</td>\n",
       "      <td>0</td>\n",
       "      <td>Collecting data from nurseries and yield trial...</td>\n",
       "      <td>Research Associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>John Holland</td>\n",
       "      <td>Operating across Australia, New Zealand and So...</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>0</td>\n",
       "      <td>Talent &amp; Performance Data Analyst. Analyses da...</td>\n",
       "      <td>Talent &amp; Performance Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>University Of Western Australia</td>\n",
       "      <td>Faculty of Engineering and Mathematical Scienc...</td>\n",
       "      <td>Crawley WA</td>\n",
       "      <td>0</td>\n",
       "      <td>Faculty of Engineering and Mathematical Scienc...</td>\n",
       "      <td>Research Associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Westpac Group</td>\n",
       "      <td>Westpac has an immediate opportunity for a Pla...</td>\n",
       "      <td>Sydney Central Business District NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Warehouses, Business Intelligence, Master...</td>\n",
       "      <td>Platform Product Owner, Big Data, App Dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Plus Consulting</td>\n",
       "      <td>Business Intelligence Junior Developer/Mid Lev...</td>\n",
       "      <td>Melbourne VIC</td>\n",
       "      <td>1</td>\n",
       "      <td>Business Intelligence and Data Warehouse. Univ...</td>\n",
       "      <td>Business Intelligence Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>NRMA Motoring &amp; Services</td>\n",
       "      <td>Our Members enjoy our legendary roadside assis...</td>\n",
       "      <td>Sydney Olympic Park NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Degree in Computer Science, Business or equiva...</td>\n",
       "      <td>Digital Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Macquarie Group Limited</td>\n",
       "      <td>About the role\\n\\nAn exciting opportunity has ...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>0</td>\n",
       "      <td>As a key member of the Decision Science team, ...</td>\n",
       "      <td>Risk Analyst, Credit Risk Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Takeda Pharmaceutical</td>\n",
       "      <td>By clicking the “Apply” button, I understand t...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>0</td>\n",
       "      <td>Science, economics, business, statistics). Exp...</td>\n",
       "      <td>Business Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Public Transport Victoria</td>\n",
       "      <td>About Us\\nPublic Transport Victoria (PTV) is a...</td>\n",
       "      <td>Melbourne City Centre VIC</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Analytics, Information Systems and Geospa...</td>\n",
       "      <td>Bus Data Information Coordinator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Open Colleges</td>\n",
       "      <td>The Business Intelligence Analyst role is resp...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Guardian – responsible for all the compan...</td>\n",
       "      <td>Business Intelligence Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Job Category                                      company  \\\n",
       "1    Data Science                                       Metigy   \n",
       "2    Data Science                                          HDR   \n",
       "3    Data Science  International Institute of Data & Analytics   \n",
       "4    Data Science                                   SAI Global   \n",
       "5    Data Science                                      Velrada   \n",
       "6    Data Science                                   BuildingIQ   \n",
       "7    Data Science                               Fortune Select   \n",
       "8    Data Science                         BCG Digital Ventures   \n",
       "9    Data Science                                         Arup   \n",
       "10   Data Science                                   SiteMinder   \n",
       "12   Data Science                                       Google   \n",
       "13   Data Science                                     Sterning   \n",
       "14   Data Science                                QBE Insurance   \n",
       "15   Data Science                   The Yield AgTech Solutions   \n",
       "20   Data Science                                          HDR   \n",
       "21   Data Science                       Qantas Airways Limited   \n",
       "22   Data Science                                         KPMG   \n",
       "23   Data Science                                         KPMG   \n",
       "24   Data Science                                       Google   \n",
       "25   Data Science                                   The Iconic   \n",
       "26   Data Science                                    Microsoft   \n",
       "27   Data Science                                         nbn™   \n",
       "28   Data Science                           Melbourne IT Group   \n",
       "35   Data Science                                Wipro Limited   \n",
       "36   Data Science                                   HelloFresh   \n",
       "37   Data Science                          Capgemini Australia   \n",
       "39   Data Science                       Healthdirect Australia   \n",
       "40   Data Science                                   Amazon.com   \n",
       "41   Data Science                                    CS Energy   \n",
       "42   Data Science                                    Infoready   \n",
       "..            ...                                          ...   \n",
       "134  Data Science                                   Piktochart   \n",
       "136  Data Science                                       Coffey   \n",
       "137  Data Science                            ANZ Banking Group   \n",
       "138  Data Science                                       Cardno   \n",
       "139  Data Science                                 Domain Group   \n",
       "147  Data Science                                Akuna Capital   \n",
       "150  Data Science       Pharmaceutical & Medical Professionals   \n",
       "152  Data Science                                   Amazon.com   \n",
       "153  Data Science                                Akuna Capital   \n",
       "154  Data Science                                Akuna Capital   \n",
       "155  Data Science                  Children's Cancer Institute   \n",
       "156  Data Science                                     Georgiou   \n",
       "163  Data Science                                        Optus   \n",
       "164  Data Science                                      Servian   \n",
       "166  Data Science        Johnson & Johnson Family of Companies   \n",
       "168  Data Science                                          IBM   \n",
       "172  Data Science                  Children's Cancer Institute   \n",
       "180  Data Science                              Digital Alchemy   \n",
       "181  Data Science                                         DELL   \n",
       "184  Data Science                          Cushman & Wakefield   \n",
       "187  Data Science                                       DuPont   \n",
       "188  Data Science                                 John Holland   \n",
       "194  Data Science              University Of Western Australia   \n",
       "195  Data Science                                Westpac Group   \n",
       "197  Data Science                              Plus Consulting   \n",
       "198  Data Science                     NRMA Motoring & Services   \n",
       "200  Data Science                      Macquarie Group Limited   \n",
       "201  Data Science                        Takeda Pharmaceutical   \n",
       "202  Data Science                    Public Transport Victoria   \n",
       "203  Data Science                                Open Colleges   \n",
       "\n",
       "                                           description  \\\n",
       "1    @metigy we are creating the next generation of...   \n",
       "2    HDR specializes in architecture, engineering, ...   \n",
       "3    The International Institute of Data & Analytic...   \n",
       "4    At SAI Global, we make Intelligent Risk possib...   \n",
       "5    Giving you the platform to succeed:\\nWorking o...   \n",
       "6    Job Description | Location – Sydney, Australia...   \n",
       "7    Location: Sydney\\n\\nJob Type: Permanent\\n\\nSki...   \n",
       "8    Syphen is on the mission to unlock the potenti...   \n",
       "9    Data Scientist (SYDDO)\\nPrimary Location: Aust...   \n",
       "10   SiteMinder is the chosen solution for over , h...   \n",
       "12   Google Technical Services: Professional Servic...   \n",
       "13   This is an amazing opportunity to step out fro...   \n",
       "14   Apply scientific principles to business proces...   \n",
       "15   About us\\nThe Yield is hiring. Come join us to...   \n",
       "20   Data Scientist - ()\\nDescription\\n\\nHDR specia...   \n",
       "21   Data Scientist\\nGreenfield Data Science roles ...   \n",
       "22   Be a key part of our growth & innovation strat...   \n",
       "23   Leadership opportunity in consulting (Associat...   \n",
       "24   Google's software engineers develop the next-g...   \n",
       "25   THE ICONIC is a truly unique brand. We entered...   \n",
       "26   The Microsoft Malware Protection Center (MMPC)...   \n",
       "27   As nbn is moving to the scale phase, in parall...   \n",
       "28   Apply now\\n\\nDiscipline:\\nData and Analytics\\n...   \n",
       "35   Wipro's Data Scientists help our clients disco...   \n",
       "36   About HelloFresh\\n\\nWe are the leading global ...   \n",
       "37   About the role\\nWe are looking for a Data Scie...   \n",
       "39   The Data Analyst extracts, analyses and interp...   \n",
       "40   Business today operates at the pinnacle of the...   \n",
       "41   Back to Current Vacancies\\n\\nData Scientist\\n\\...   \n",
       "42   This is an opportunity for you to join Austral...   \n",
       "..                                                 ...   \n",
       "134  The team in charged of data analysis in Piktoc...   \n",
       "136  This role is more than a desk job. It’s about ...   \n",
       "137  Willing to learn/train in Hadoop (Cloudera) ad...   \n",
       "138  Job Description\\nCardno is an ASX listed profe...   \n",
       "139  A little about us:\\nThere has never been a mor...   \n",
       "147  About Akuna:\\nAkuna Capital is a young and boo...   \n",
       "150  Ongoing assignment offering full time hours.\\n...   \n",
       "152  Amazon has an immediate opening for an FBA Sup...   \n",
       "153  About Akuna:\\nAkuna Capital is a young and boo...   \n",
       "154  About Akuna:\\nAkuna Capital is a young and boo...   \n",
       "155  Innovative, collaborative and positive team-or...   \n",
       "156  Georgiou is a national building construction a...   \n",
       "163  Join a company dedicated to your career develo...   \n",
       "164  The opportunity\\nThis is a great opportunity f...   \n",
       "166  Permanent role\\nLeading products - Gastroenter...   \n",
       "168  Job Description\\nResearch Scientist- AI Soluti...   \n",
       "172  Innovative, collaborative and positive team-or...   \n",
       "180  We're looking for a consultative individual wh...   \n",
       "181  Graduate Opportunities at Dell EMC (x  roles)\\...   \n",
       "184  The Data & Reporting Analyst is a client Accou...   \n",
       "187  Pioneer uses the science of the lab and the la...   \n",
       "188  Operating across Australia, New Zealand and So...   \n",
       "194  Faculty of Engineering and Mathematical Scienc...   \n",
       "195  Westpac has an immediate opportunity for a Pla...   \n",
       "197  Business Intelligence Junior Developer/Mid Lev...   \n",
       "198  Our Members enjoy our legendary roadside assis...   \n",
       "200  About the role\\n\\nAn exciting opportunity has ...   \n",
       "201  By clicking the “Apply” button, I understand t...   \n",
       "202  About Us\\nPublic Transport Victoria (PTV) is a...   \n",
       "203  The Business Intelligence Analyst role is resp...   \n",
       "\n",
       "                                 location  salary  \\\n",
       "1                         Sydney NSW 2000       1   \n",
       "2                         Sydney NSW 2000       1   \n",
       "3                              Sydney NSW       1   \n",
       "4                              Sydney NSW       1   \n",
       "5                           Melbourne VIC       1   \n",
       "6                              Sydney NSW       1   \n",
       "7                              Sydney NSW       1   \n",
       "8                              Sydney NSW       1   \n",
       "9                              Sydney NSW       1   \n",
       "10                             Sydney NSW       1   \n",
       "12                             Sydney NSW       1   \n",
       "13                        Sydney NSW 2000       1   \n",
       "14                        Sydney NSW 2000       1   \n",
       "15                        Sydney NSW 2000       1   \n",
       "20                       North Sydney NSW       1   \n",
       "21                             Sydney NSW       1   \n",
       "22                             Sydney NSW       1   \n",
       "23                             Sydney NSW       1   \n",
       "24                             Sydney NSW       1   \n",
       "25                              Australia       1   \n",
       "26                          Melbourne VIC       1   \n",
       "27                          Melbourne VIC       1   \n",
       "28                          Melbourne VIC       1   \n",
       "35                          Melbourne VIC       1   \n",
       "36                             Sydney NSW       0   \n",
       "37                            Adelaide SA       1   \n",
       "39   Sydney Central Business District NSW       0   \n",
       "40                             Sydney NSW       1   \n",
       "41                           Brisbane QLD       1   \n",
       "42                          Melbourne VIC       1   \n",
       "..                                    ...     ...   \n",
       "134                         Melbourne VIC       1   \n",
       "136                          Brisbane QLD       0   \n",
       "137                         Melbourne VIC       1   \n",
       "138                            Queensland       0   \n",
       "139                            Sydney NSW       1   \n",
       "147                            Sydney NSW       1   \n",
       "150                            Sydney NSW       0   \n",
       "152                            Sydney NSW       0   \n",
       "153                            Sydney NSW       1   \n",
       "154                            Sydney NSW       1   \n",
       "155                            Sydney NSW       0   \n",
       "156                            Sydney NSW       1   \n",
       "163                            Sydney NSW       1   \n",
       "164                            Sydney NSW       1   \n",
       "166                         Melbourne VIC       0   \n",
       "168                         Melbourne VIC       1   \n",
       "172                            Sydney NSW       0   \n",
       "180                            Sydney NSW       1   \n",
       "181                        North Ryde NSW       0   \n",
       "184                       New South Wales       0   \n",
       "187                           Wyreema QLD       0   \n",
       "188                       New South Wales       0   \n",
       "194                            Crawley WA       0   \n",
       "195  Sydney Central Business District NSW       1   \n",
       "197                         Melbourne VIC       1   \n",
       "198               Sydney Olympic Park NSW       1   \n",
       "200                            Sydney NSW       0   \n",
       "201                            Sydney NSW       0   \n",
       "202             Melbourne City Centre VIC       0   \n",
       "203                            Sydney NSW       1   \n",
       "\n",
       "                                               summary  \\\n",
       "1    Because of the nature of our platform, Data Sc...   \n",
       "2    Continuously learn and develop new skills in d...   \n",
       "3    In data science and big data analytics, the ID...   \n",
       "4    Analytics or data science team in a commercial...   \n",
       "5    With a background in development across Data M...   \n",
       "6    We are looking for a Data Scientist to be a pa...   \n",
       "7    3+ years proven career history in Data science...   \n",
       "8    Significant experience in data science field. ...   \n",
       "9    Experience in applying data science methods to...   \n",
       "10   Data science, analytics, economic consulting);...   \n",
       "12   Engage various stakeholders, assess data readi...   \n",
       "13   This is an amazing opportunity to step out fro...   \n",
       "14   Good understanding of Data Science domain, sta...   \n",
       "15   Time series data, predictive atmospheric model...   \n",
       "20   Continuously learn and develop new skills in d...   \n",
       "21   Greenfield Data Science roles in this fast gro...   \n",
       "22   Using Data Science techniques and Machine Lear...   \n",
       "23   Using Data Science techniques and Machine Lear...   \n",
       "24   BS degree in Computer Science, similar technic...   \n",
       "25   At The Iconic, we’d like to think of our Data ...   \n",
       "26   A Masters or Ph.D degree with coursework in St...   \n",
       "27   Work closely with data engineers to supporting...   \n",
       "28   Data and Analytics. At InfoReady we’re passion...   \n",
       "35   Experience with common data science toolkits, ...   \n",
       "36   You have at least 1-year previous experience w...   \n",
       "37   Experience using Data Science tools (e.g. Clou...   \n",
       "39   Effective management of assigned Healthdirect ...   \n",
       "40   The successful candidate is an engineer with a...   \n",
       "41   As a member of the Asset Analytics team, the D...   \n",
       "42   Data Vizualisation experience. At InfoReady we...   \n",
       "..                                                 ...   \n",
       "134  Performed in-depth analyses on data of various...   \n",
       "136  Tertiary qualifications in Science, Environmen...   \n",
       "137  Experience in data warehousing concepts, files...   \n",
       "138  Analysis and presentation of data. A keen inte...   \n",
       "139  MS or PhD degree in Computer Science, Artifici...   \n",
       "147  Masters or PhD in Statistics, Computer Science...   \n",
       "150  Data entry into current system. A Medical Scie...   \n",
       "152  Ability to analyze data and metrics. Bachelor’...   \n",
       "153  Being a Quantitative Developer with the Data t...   \n",
       "154  Being a Quantitative Developer with the Data t...   \n",
       "155  Experience with microarrays, next-generation s...   \n",
       "156  Assisting in data entry, coordinating monthly ...   \n",
       "163  Mastery of calling APIs, ingesting data, trans...   \n",
       "164  Data & Analytics - BI/DW, Big Data Analytics, ...   \n",
       "166  Medical Science Liaison. As a Medical Science ...   \n",
       "168  At least two years of experience after a Docto...   \n",
       "172  Tertiary qualifications in science or relevant...   \n",
       "180  Relevant degree in Computer Science, ICT, Scie...   \n",
       "181  Computer Science or Engineering degree (gradua...   \n",
       "184  Document data reporting processes and identify...   \n",
       "187  Collecting data from nurseries and yield trial...   \n",
       "188  Talent & Performance Data Analyst. Analyses da...   \n",
       "194  Faculty of Engineering and Mathematical Scienc...   \n",
       "195  Data Warehouses, Business Intelligence, Master...   \n",
       "197  Business Intelligence and Data Warehouse. Univ...   \n",
       "198  Degree in Computer Science, Business or equiva...   \n",
       "200  As a key member of the Decision Science team, ...   \n",
       "201  Science, economics, business, statistics). Exp...   \n",
       "202  Data Analytics, Information Systems and Geospa...   \n",
       "203  Data Guardian – responsible for all the compan...   \n",
       "\n",
       "                                                 title  \n",
       "1                                  Lead Data Scientist  \n",
       "2                                       Data Scientist  \n",
       "3                        Junior Data Analyst/Scientist  \n",
       "4                                       Data Scientist  \n",
       "5                                       Data Scientist  \n",
       "6                                       Data Scientist  \n",
       "7                                       Data Scientist  \n",
       "8      Data Scientist - Machine Learning Data Platform  \n",
       "9                                       Data Scientist  \n",
       "10                                      Data Scientist  \n",
       "12           Data Scientist, Google Technical Services  \n",
       "13                                      Data Scientist  \n",
       "14                                      Data Scientist  \n",
       "15                                      Data Scientist  \n",
       "20                                      Data Scientist  \n",
       "21                                      Data Scientist  \n",
       "22                                    Data & Analytics  \n",
       "23                  Data & Analytics - Leadership role  \n",
       "24                                   Software Engineer  \n",
       "25                                      Data Scientist  \n",
       "26                            Data & Applied Scientist  \n",
       "27                                      Data Scientist  \n",
       "28                                      Data Scientist  \n",
       "35                                      Data Scientist  \n",
       "36                    Junior Data Analyst - Internship  \n",
       "37                                      Data Scientist  \n",
       "39                   Junior-Data-and-Reporting-Analyst  \n",
       "40                                  Research Scientist  \n",
       "41                                      Data Scientist  \n",
       "42                                      Data Scientist  \n",
       "..                                                 ...  \n",
       "134                                       Data Analyst  \n",
       "136                            Environmental Scientist  \n",
       "137                         Big Data Platform Engineer  \n",
       "138                            Environmental Scientist  \n",
       "139               Software Engineer - Machine Learning  \n",
       "147  Junior Quantitative Researcher - Machine Learning  \n",
       "150                           Medical Science Graduate  \n",
       "152                     Process Analyst - Supply Chain  \n",
       "153  Quantitative Developer- Data Analysis, Cryptoc...  \n",
       "154              Quantitative Developer- Data Analysis  \n",
       "155          Bioinformatician/ Computational Biologist  \n",
       "156                                Environmental Cadet  \n",
       "163                              Senior Data Scientist  \n",
       "164                                    Data Consultant  \n",
       "166                         Medical Scientific Liaison  \n",
       "168         Research Scientist- AI Solutions Melbourne  \n",
       "172      Research Assistant - Molecular Profiling (PM)  \n",
       "180                                   Business Analyst  \n",
       "181   Graduate Technical Support Engineer (x 24 roles)  \n",
       "184                           Data & Reporting Analyst  \n",
       "187                                 Research Associate  \n",
       "188                  Talent & Performance Data Analyst  \n",
       "194                                 Research Associate  \n",
       "195          Platform Product Owner, Big Data, App Dev  \n",
       "197                    Business Intelligence Developer  \n",
       "198                                  Digital Developer  \n",
       "200                Risk Analyst, Credit Risk Analytics  \n",
       "201                                   Business Analyst  \n",
       "202                   Bus Data Information Coordinator  \n",
       "203                      Business Intelligence Analyst  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Articles_nan_Salary.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analizing our results, we can say our model works very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's append the two dataframes, the one with the salaries and the one that got the predictions we've made to do our next excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Appends two dataframes\n",
    "Articles_nan_Salary = Articles_nan_Salary.append(salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What We are gonna do now is to get the job titles we would like to analyze and edit the dataframe that will contain only our jobs Articles  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6673, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates a new column with the title information and make all the words lower case.\n",
    "Articles_nan_Salary[\"Job_Title\"]=Articles_nan_Salary[\"title\"]\n",
    "Articles_nan_Salary[\"Job_Title\"]= Articles_nan_Salary[\"Job_Title\"].str.lower()\n",
    "Articles_nan_Salary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6673, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Articles_nan_Salary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Searchs the words in the dataframe and return the Articles that contain those words\n",
    "def search(df, *words):\n",
    "   \"\"\"\n",
    "   Return a sub-DataFrame of those rows whose Name column match all the words.\n",
    "   \"\"\"\n",
    "   return df[np.logical_and.reduce([df.str.contains(word) for word in words])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Articles_nan_Salary.loc[search(Articles_nan_Salary[\"Job_Title\"],\"junior\",\"data\",\"sci\").index,\"Job_Title\"] = \"junior data science\"\n",
    "Articles_nan_Salary.loc[search(Articles_nan_Salary[\"Job_Title\"],\"data\",\"sci\",\"senior\").index,\"Job_Title\"] = \"senior data Science\"\n",
    "Articles_nan_Salary.loc[search(Articles_nan_Salary[\"Job_Title\"],\"softw\",\"engin\").index,\"Job_Title\"] = \"Software Engineer\"\n",
    "Articles_nan_Salary.loc[search(Articles_nan_Salary[\"Job_Title\"],\"junior\",\"data\", \"analy\").index,\"Job_Title\"] = \"Junior Data Analyst\"\n",
    "Articles_nan_Salary.loc[search(Articles_nan_Salary[\"Job_Title\"],\"business\",\"analyst\").index,\"Job_Title\"] = \"Business Analyst\"\n",
    "Articles_nan_Salary.loc[search(Articles_nan_Salary[\"Job_Title\"],\"data\",\"sci\", \"lead\").index,\"Job_Title\"] = \"Lead data Scientist\"\n",
    "Articles_nan_Salary.loc[search(Articles_nan_Salary[\"Job_Title\"],\"data\",\"big\").index,\"Job_Title\"] = \"Big Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Category</th>\n",
       "      <th>Salary_type</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_mean</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>Job_Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>International Institute of Data &amp; Analytics</td>\n",
       "      <td>The International Institute of Data &amp; Analytic...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In data science and big data analytics, the ID...</td>\n",
       "      <td>Junior Data Analyst/Scientist</td>\n",
       "      <td>junior data science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Google</td>\n",
       "      <td>Google's software engineers develop the next-g...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BS degree in Computer Science, similar technic...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Software Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HelloFresh</td>\n",
       "      <td>About HelloFresh\\n\\nWe are the leading global ...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>You have at least 1-year previous experience w...</td>\n",
       "      <td>Junior Data Analyst - Internship</td>\n",
       "      <td>Junior Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Healthdirect Australia</td>\n",
       "      <td>The Data Analyst extracts, analyses and interp...</td>\n",
       "      <td>Sydney Central Business District NSW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Effective management of assigned Healthdirect ...</td>\n",
       "      <td>Junior-Data-and-Reporting-Analyst</td>\n",
       "      <td>Junior Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Google</td>\n",
       "      <td>The Google Cloud Platform team helps customers...</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 years of experience building machine learnin...</td>\n",
       "      <td>Strategic Cloud Engineer, Machine Learning and...</td>\n",
       "      <td>Big Data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Job Category  Salary_type                                      company  \\\n",
       "3   Data Science          NaN  International Institute of Data & Analytics   \n",
       "24  Data Science          NaN                                       Google   \n",
       "36  Data Science          NaN                                   HelloFresh   \n",
       "39  Data Science          NaN                       Healthdirect Australia   \n",
       "83  Data Science          NaN                                       Google   \n",
       "\n",
       "                                          description  \\\n",
       "3   The International Institute of Data & Analytic...   \n",
       "24  Google's software engineers develop the next-g...   \n",
       "36  About HelloFresh\\n\\nWe are the leading global ...   \n",
       "39  The Data Analyst extracts, analyses and interp...   \n",
       "83  The Google Cloud Platform team helps customers...   \n",
       "\n",
       "                                location  salary  salary_mean  \\\n",
       "3                             Sydney NSW     1.0          NaN   \n",
       "24                            Sydney NSW     1.0          NaN   \n",
       "36                            Sydney NSW     0.0          NaN   \n",
       "39  Sydney Central Business District NSW     0.0          NaN   \n",
       "83                            Sydney NSW     1.0          NaN   \n",
       "\n",
       "                                              summary  \\\n",
       "3   In data science and big data analytics, the ID...   \n",
       "24  BS degree in Computer Science, similar technic...   \n",
       "36  You have at least 1-year previous experience w...   \n",
       "39  Effective management of assigned Healthdirect ...   \n",
       "83  3 years of experience building machine learnin...   \n",
       "\n",
       "                                                title            Job_Title  \n",
       "3                       Junior Data Analyst/Scientist  junior data science  \n",
       "24                                  Software Engineer    Software Engineer  \n",
       "36                   Junior Data Analyst - Internship  Junior Data Analyst  \n",
       "39                  Junior-Data-and-Reporting-Analyst  Junior Data Analyst  \n",
       "83  Strategic Cloud Engineer, Machine Learning and...             Big Data  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates a list of the jobs \n",
    "list_jobs= [\"junior data science\", \"senior data Science\", \"Software Engineer\", \"Junior Data Analyst\",\"Business Analyst\"\n",
    "           \"Lead data Scientist\", \"Big Data\"]\n",
    "#Get's the Articles where the job title is in the list \n",
    "Articles_nan_Salary = Articles_nan_Salary[Articles_nan_Salary[\"Job_Title\"].isin(list_jobs)]\n",
    "Articles_nan_Salary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Articles_nan_Salary.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's train our models ans see how they perform with this new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = Articles_nan_Salary[\"description\"]\n",
    "y = Articles_nan_Salary[\"Job_Title\"]\n",
    "\n",
    "# split the new DataFrame into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['junior data science', 'Software Engineer', 'Junior Data Analyst',\n",
       "       'Big Data', 'senior data Science'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = y.unique()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "Hashing Vectorizer and Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noelialopez83/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/noelialopez83/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/noelialopez83/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84375\n",
      "-----------------------------------------------------------------------------------------\n",
      "TfidfVectorizer using (1, 2) ngram and Logistic Regression\n",
      "Accuracy: 0.8359375\n",
      "-----------------------------------------------------------------------------------------\n",
      "CountVectorizer with (1, 2) ngram and Logistic Regression\n",
      "Accuracy: 0.9609375\n",
      "Accuracy: 0.9609375\n",
      "-----------------------------------------------------------------------------------------\n",
      "CountVectorizer with LemmaTokenizer and (1, 2) ngram and Logistic Regression\n",
      "Accuracy: 0.9609375\n",
      "-----------------------------------------------------------------------------------------\n",
      "CountVectorizer with (1, 2) and MultinomialNB Regression\n",
      "Accuracy: 0.9609375\n",
      "-----------------------------------------------------------------------------------------\n",
      "CountVectorizer with (1, 2) and Random Forest Regression\n",
      "Accuracy: 0.953125\n",
      "-----------------------------------------------------------------------------------------\n",
      "CountVectorizer with (1, 2) and Decision Tree\n",
      "Accuracy: 0.9609375\n",
      "-----------------------------------------------------------------------------------------\n",
      "CountVectorizer with (1, 2) and AdaBoost\n",
      "Accuracy: 0.7734375\n",
      "-----------------------------------------------------------------------------------------\n",
      "TfidfVectorizer using (1, 2) ngram and DecisionTreeClassifier\n",
      "Accuracy: 0.96875\n",
      "-----------------------------------------------------------------------------------------\n",
      "TfidfVectorizer using (1, 2) ngram and RandomForestClassifier\n",
      "Accuracy: 0.9453125\n",
      "-----------------------------------------------------------------------------------------\n",
      "CountVectorizer with LemmaTokenizer with (1, 2) and SVM\n",
      "Accuracy: 0.9765625\n"
     ]
    }
   ],
   "source": [
    "Models_Acc(X_train, y_train, X_test, y_test, ngramRange=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see Count Vectorizer with Logistic regression get the best score of 1,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9609375"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X = Articles_nan_Salary[\"description\"]\n",
    "y = Articles_nan_Salary[\"Job_Title\"]\n",
    "\n",
    "# split the new DataFrame into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=101)\n",
    "# Lets use the stop_words argument to remove words like \"and, the, a\"\n",
    "cvec = CountVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "\n",
    "# Fit our vectorizer using our train data\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train = pd.DataFrame(cvec.transform(X_train).todense(),\n",
    "                       columns=cvec.get_feature_names())\n",
    "X_test = pd.DataFrame(cvec.transform(X_test).todense(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "#Import and fit our logistic regression and test it too\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31  0  0  0  2]\n",
      " [ 0  6  1  0  0]\n",
      " [ 2  0 69  0  0]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  0  0 12]]\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           Big Data       0.94      0.94      0.94        33\n",
      "Junior Data Analyst       1.00      0.86      0.92         7\n",
      "  Software Engineer       0.99      0.97      0.98        71\n",
      "junior data science       1.00      1.00      1.00         5\n",
      "senior data Science       0.86      1.00      0.92        12\n",
      "\n",
      "        avg / total       0.96      0.96      0.96       128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lr.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>big data</th>\n",
       "      <td>0.470840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big</th>\n",
       "      <td>0.444034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hadoop</th>\n",
       "      <td>0.316142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience</th>\n",
       "      <td>0.306888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloud</th>\n",
       "      <td>0.252827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>devops</th>\n",
       "      <td>0.146875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solutions</th>\n",
       "      <td>0.146405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years</th>\n",
       "      <td>0.136193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leading</th>\n",
       "      <td>0.129091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>program</th>\n",
       "      <td>0.122685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technology</th>\n",
       "      <td>0.110606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spark</th>\n",
       "      <td>0.108820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>managing</th>\n",
       "      <td>0.100285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef\n",
       "big data    0.470840\n",
       "big         0.444034\n",
       "hadoop      0.316142\n",
       "experience  0.306888\n",
       "cloud       0.252827\n",
       "devops      0.146875\n",
       "solutions   0.146405\n",
       "years       0.136193\n",
       "leading     0.129091\n",
       "program     0.122685\n",
       "technology  0.110606\n",
       "spark       0.108820\n",
       "managing    0.100285"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns  =  np.array(cvec.get_feature_names())\n",
    "\n",
    "def list_important_pred_var(data):\n",
    "    important_pred_var = pd.DataFrame(data, columns = [\"coef\"], index = columns)\n",
    "    return important_pred_var.sort_values([\"coef\"], ascending = False)[:30]\n",
    "\n",
    "list_important_pred_var(lr.coef_[0]).head(13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = salary['summary']\n",
    "y = salary.salary_mean\n",
    "# use CountVectorizer to create document-term matrices from X_train and X_test\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "# Fit our vectorizer using our train data\n",
    "X = cv.fit_transform(X)\n",
    "\n",
    "# splits the new DataFrame into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# machine learning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.fit(X_train,y_train)\n",
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,u'Predicted Y')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13e389510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test,predictions)\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Predicted Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_r2(y, yhat):\n",
    "    # estimated error \n",
    "    err_tot = (y-np.mean(y))**2\n",
    "    # residual error\n",
    "    err_res = (y - yhat)**2\n",
    "    # total sum of squares\n",
    "    ss_tot = np.sum(err_tot)\n",
    "    # residual sum of squares\n",
    "    ss_res = np.sum(err_res)\n",
    "    return 1 - (ss_res/ss_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3371010267434851"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_r2(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
